{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6b81ae8c",
   "metadata": {},
   "source": [
    "### 순서\n",
    "1. 문서의 내용을 읽는다.\n",
    "2. 문서를 쪼갠다.\n",
    "    - 토큰수 초과로 답변을 생성하지 못할 수 있고\n",
    "    - 문서가 길면(입력이 길면) 답변 생성이 오래걸림\n",
    "3. 임베딩 -> 벡터 데이터베이스에 저장\n",
    "4. 질문이 있을 때, 벡터 데이터베이스에 유사도 검색\n",
    "5. 유사도 검색으로 가져온 문서를 LLM에 질문과 함께 전달"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "79d2a9ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install -qU  docx2txt langchain_community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f7fbcf83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install -qU langchain-text-splitters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f5d3b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import Docx2txtLoader\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1500,\n",
    "    chunk_overlap=200,\n",
    ")\n",
    "\n",
    "loader = Docx2txtLoader(\"./tax.docx\")\n",
    "document = loader.load() # chunking 없이 한번에 불러옴\n",
    "document_list = loader.load_and_split(text_splitter=text_splitter) # chunking 하여 불러옴"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "712d6deb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(document) # chunking 없이 한번에 불러옴\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9dda1227",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "194"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(document_list) # chunking 하여 불러옴"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "18afe21f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "embedding = GoogleGenerativeAIEmbeddings(model=\"models/gemini-embedding-001\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8d252b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install -qU langchain-chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "90c0fd26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install langchain-pinecone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ffdde3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from pinecone import Pinecone\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "\n",
    "# INDEX_NAME = \"tax-index\"\n",
    "PINECONE_API_KEY = os.environ.get(\"PINECONE_API_KEY\")\n",
    "pc = Pinecone(api_key=PINECONE_API_KEY)\n",
    "\n",
    "index = pc.Index(INDEX_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cde4e239",
   "metadata": {},
   "outputs": [],
   "source": [
    "database = PineconeVectorStore(index=index, embedding=embedding)\n",
    "database.add_documents(document_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6d394c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"연봉 5천만원인 직장인의 소득세는 얼마인가요?\"\n",
    "retrieved_docs = database.similarity_search(query, k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "03178a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87934bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt = f\"\"\"[identity]\n",
    "# - 당신은 최그의 한국 소득세 전문가입니다\n",
    "# - [context]를 참고해서 사용자의 질문에 답변해주세요\n",
    "\n",
    "# [context]\n",
    "# {retrieved_docs}\n",
    "\n",
    "# question: {query}\n",
    "# \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84eb04bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ai_message = llm.invoke(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d436939f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ai_message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fac8ce88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "LANGSMITH_API_KEY = os.getenv(\"LANGSMITH_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ce1d336f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langsmith import Client\n",
    "\n",
    "client = Client(api_key=LANGSMITH_API_KEY)\n",
    "\n",
    "prompt = client.pull_prompt(\"rlm/rag-prompt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "95e2c6e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, metadata={'lc_hub_owner': 'rlm', 'lc_hub_repo': 'rag-prompt', 'lc_hub_commit_hash': '50442af133e61576e74536c6556cefe1fac147cad032f4377b60c436e6cdcb6e'}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, template=\"You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\\nQuestion: {question} \\nContext: {context} \\nAnswer:\"), additional_kwargs={})])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fda0806",
   "metadata": {},
   "source": [
    "# 여기서부터 중단.\n",
    "\n",
    "(문제1-해결)hub이 deprecate 됐고 langsmith를 대체로 활용해야하는데 문서가 복잡해 일단 hub를 왜 쓰는지에 대한 다음 강의 수강후 다시 돌아와 문서 공부 필요.  \n",
    "\n",
    "\n",
    "(문제2)RetrievalQA 가 deprecate 됐는데 이게 뭘 하는 건지, 그리고 뭔지 모르니 뭘로 대체해야 할지도 모르는 상태.\n",
    "\n",
    "관련 검색:\n",
    "- 검색어 RetrievalQA\n",
    "- 검색어 RetrievalQA.from_chain_type()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3b04195",
   "metadata": {},
   "source": [
    "### 1. 레거시 retrievalQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c133503a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain.chains import RetrievalQA\n",
    "\n",
    "# qa_chain = RetrievalQA.from_chain_type(\n",
    "#     llm, \n",
    "#     retriever=database.as_retriever(),\n",
    "#     chain_type_kwargs={\"prompt\": prompt}\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e76d696",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ai_message = qa_chain({\"query\": query})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d2dfa9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ai_message"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ace14dc2",
   "metadata": {},
   "source": [
    "### 2. langchain 공식문서 검색에서 찾은 agent 방식(불가)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00a0b03b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain.agents import create_agent\n",
    "\n",
    "# tools = [retrieve_context]\n",
    "# # If desired, specify custom instructions\n",
    "# prompt = (\n",
    "#     \"You have access to a tool that retrieves context from a blog post. \"\n",
    "#     \"Use the tool to help answer user queries.\"\n",
    "# )\n",
    "\n",
    "# agent = create_agent(llm, database, system_prompt=prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf7e5f0e",
   "metadata": {},
   "source": [
    "### 3. gpt 질의 통해 얻은 LCEL 방식"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "60bc407d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "제공된 소득세법 조항에는 연봉 5천만원 직장인의 소득세를 직접 명시하거나 계산한 내용은 없습니다. 다만, 근로소득공제, 세율, 근로소득세액공제 등 소득세 계산에 필요한 규정들이 설명되어 있습니다. 따라서 해당 정보만으로는 정확한 소득세를 알 수 없습니다.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# 1. Retriever 설정 (검색기)\n",
    "retriever = database.as_retriever()\n",
    "\n",
    "# 2. 문서들을 하나로 합치는 헬퍼 함수\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "# 3. LCEL 체인 구성 (이것이 현대적인 RetrievalQA입니다)\n",
    "# 흐름: {context: 검색결과, question : 질문} -> 프롬프트 -> LLM -> 문자열 변환\n",
    "rag_chain = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# 4. 실행\n",
    "# invoke에 문자열(query)만 넣으면 RunnablePassthrough가 받아서 처리합니다.\n",
    "ai_message = rag_chain.invoke(query)\n",
    "\n",
    "print(ai_message)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag-basics",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
